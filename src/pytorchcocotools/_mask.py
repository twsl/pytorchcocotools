from typing import Annotated, cast

import torch
from torch import Tensor
from torchvision import tv_tensors as tv

from pytorchcocotools.internal.entities import RLE, IoUObject, Poly, PyObj, RleObj, RleObjs, RLEs, TorchDevice
from pytorchcocotools.internal.mask_api import (
    bbIou,
    rleArea,
    rleDecode,
    rleEncode,
    rleFrBbox,
    rleFrPoly,
    rleFrString,
    rleIou,
    rleMerge,
    rleToBbox,
    rleToString,
)
from pytorchcocotools.utils.list import is_list_of_type
from pytorchcocotools.utils.poly import Polygon, Polygons


def _toString(  # noqa: N802
    rles: RLEs,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObjs:
    """Internal conversion from Python RLEs object to compressed RLE format.

    Args:
        rles: The masks to encode.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The RLE encoded mask.
    """
    objs = [
        RleObj(
            size=[r.h, r.w],
            counts=rleToString(
                r,
                device=device,
                requires_grad=requires_grad,
            ),
        )
        for r in rles
    ]
    return objs


def _frString(  # noqa: N802
    rle_objs: RleObjs,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RLEs:
    """Internal conversion from compressed RLE format to Python RLEs object.

    Args:
        rle_objs: List of rle encoded masks.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The decoded mask.
    """
    rles = [
        rleFrString(
            str.encode(obj.counts) if isinstance(obj.counts, str) else obj.counts,
            obj.size[0],
            obj.size[1],
            device=device,
            requires_grad=requires_grad,
        )
        for obj in rle_objs
    ]
    return rles


def encode(
    mask: Annotated[tv.Mask, "N H W"],
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObjs:
    """Encode mask to RLEs objects, list of RLE string can be generated by RLEs member function.

    Args:
        mask: The mask to encode.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The encoded mask.
    """
    # np.ndarray[np.uint8_t, ndim=3, mode='fortran']
    rles = rleEncode(mask, device=device, requires_grad=requires_grad)
    rle_objs = _toString(rles, device=device, requires_grad=requires_grad)
    return rle_objs


def decode(
    rle_objs: RleObjs,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> Annotated[tv.Mask, "H W N"]:
    """Decode mask from compressed list of RLE string or RLEs object.

    Args:
        rle_objs: The encoded masks.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The decoded mask.
    """
    rles = _frString(rle_objs, device=device, requires_grad=requires_grad)
    masks = rleDecode(rles, device=device, requires_grad=requires_grad)
    return masks


def merge(
    rle_objs: RleObjs,
    intersect: bool = False,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObj:
    """Merges multiple rles into one rle mask by taking union (OR) or intersection (AND).

    Args:
        rle_objs: The masks to merge.
        intersect: Whether to compute the intersection.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The merged mask.
    """
    rs = _frString(rle_objs, device=device, requires_grad=requires_grad)
    r = rleMerge(rs, intersect, device=device, requires_grad=requires_grad)
    obj = _toString([r], device=device, requires_grad=requires_grad)[0]
    return obj


def area(
    rle_objs: RleObjs,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> list[int]:
    """Compute area of encoded masks.

    Args:
        rle_objs: The masks to compute the area of.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        A list of areas of the encoded masks.
    """
    rs = _frString(rle_objs, device=device, requires_grad=requires_grad)
    a = rleArea(rs, device=device, requires_grad=requires_grad)
    return a


def iou(
    dt: IoUObject,
    gt: IoUObject,
    pyiscrowd: list[bool],
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> Annotated[Tensor, "M N"]:
    """Compute intersection over union between objects.

    Note:
    Supports function overload (RLEs-RLEs and bbox-bbox)

    Args:
        dt: The detected objects.
        gt: The ground truth objects.
        pyiscrowd: The iscrowd flag for each object.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The intersection over union between the detected and ground truth objects.
    """

    def _preproc(objs: IoUObject) -> tv.BoundingBoxes | RLEs:
        if isinstance(objs, tv.BoundingBoxes):
            return objs
        elif isinstance(objs, list):
            # check if list is in box format and convert it to torch.Tensor
            isbox = all((isinstance(obj, list | Tensor)) and (len(obj) == 4) for obj in objs)
            isrle = all(isinstance(obj, dict | RleObj) for obj in objs)
            if isbox:
                result = torch.tensor(
                    objs, dtype=torch.float32, device=device, requires_grad=requires_grad if requires_grad else False
                )
                if len(result.shape) == 1:
                    result = result.reshape((1, result.shape[0]))
                return tv.BoundingBoxes(
                    result,
                    format=tv.BoundingBoxFormat.XYWH,
                    canvas_size=(0, 0),
                    device=device,
                    requires_grad=requires_grad,
                )  # pyright: ignore[reportCallIssue]
            elif isrle:
                objs_clean = [
                    RleObj(counts=obj["counts"], size=obj["size"]) if isinstance(obj, dict) else obj for obj in objs
                ]
                return _frString(objs_clean)  # pyright: ignore[reportArgumentType]
            else:
                raise Exception("list input can be bounding box (Nx4) or RLEs ([RLE])")  # noqa: TRY002
        else:
            raise TypeError(
                "Unrecognized type. The following type: RLEs (rle), torch.Tensor (box), and list (box) are supported."
            )
        return []

    is_crowd = pyiscrowd
    dt_clean = _preproc(dt)
    gt_clean = _preproc(gt)
    m = len(dt_clean)
    n = len(gt_clean)
    crowd_length = len(is_crowd)
    assert crowd_length == n, "iou(iscrowd=) must have the same length as gt"  # noqa: S101, B101 # nosec B101
    if m == 0 or n == 0:
        return torch.tensor([], device=device, requires_grad=requires_grad if requires_grad else False)
    if type(dt_clean) is not type(gt_clean):
        raise Exception("The dt and gt should have the same data type, either RLEs, list or torch.Tensor")  # noqa: TRY002
    if is_list_of_type(dt_clean, RLE) and is_list_of_type(gt_clean, RLE):
        return rleIou(dt_clean, gt_clean, is_crowd)  # pyright: ignore[reportArgumentType]
    if isinstance(dt_clean, tv.BoundingBoxes) and isinstance(gt_clean, tv.BoundingBoxes):
        return bbIou(dt_clean, gt_clean, is_crowd)
    else:
        raise TypeError("Input data type not allowed.")  # noqa: TRY002
    return torch.tensor([])


def toBbox(  # noqa: N802
    rle_objs: RleObjs,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> tv.BoundingBoxes:
    """Compute bounding box from encoded objects.

    Args:
        rle_objs: The masks to compute the bounding box of.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The bounding box of the encoded masks.
    """
    rs = _frString(rle_objs, device=device, requires_grad=requires_grad)
    bb = rleToBbox(rs, device=device, requires_grad=requires_grad)
    return bb


def frBbox(  # noqa: N802
    bb: tv.BoundingBoxes,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObjs:
    """Convert bounding box to run length encoded objects.

    Args:
        bb: The bounding box to convert.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The RLE encoded objects.
    """
    rs = rleFrBbox(bb, device=device, requires_grad=requires_grad)
    objs = _toString(rs, device=device, requires_grad=requires_grad)
    return objs


def frPoly(  # noqa: N802
    poly: list[Polygon],
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObjs:
    """Convert polygon to run length encoded objects.

    Args:
        poly: The polygon to convert.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The RLE encoded objects.
    """
    rs = [rleFrPoly(p, device=device, requires_grad=requires_grad) for p in poly]
    objs = _toString(RLEs(rs))
    return RleObjs(objs)


def frUncompressedRLE(  # noqa: N803, N802
    uc_rles: RleObjs,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObjs:
    """Convert uncompressed RLE to run length encoded objects.

    Args:
        uc_rles: The uncompressed RLEs to convert.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The RLE encoded objects.
    """
    n = len(uc_rles)
    objs = []
    for i in range(n):
        cnts = torch.tensor(
            uc_rles[i].counts,
            dtype=torch.int,
            device=device,
            requires_grad=requires_grad if requires_grad is not None else False,
        )
        r = RLE(uc_rles[i].size[0], uc_rles[i].size[1], cnts)
        objs.append(_toString(RLEs([r]), device=device, requires_grad=requires_grad)[0])
    return objs


def frPyObjects(  # noqa: N802
    py_obj: PyObj,
    h: int,
    w: int,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObjs | RleObj:
    """Convert (list of) polygon, bbox, or uncompressed RLE to encoded RLE mask.

    Args:
        py_obj: The object(s) to convert.
        h: The height of the mask.
        w: The width of the mask.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Raises:
        Exception: Input type is not supported.

    Returns:
        The encoded mask.
    """
    # encode rle from a list of python objects
    if isinstance(py_obj, tv.BoundingBoxes):
        return frBbox(py_obj)
    elif isinstance(py_obj, Tensor):
        bbox = tv.BoundingBoxes(
            py_obj,
            format=tv.BoundingBoxFormat.XYWH,
            canvas_size=(h, w),
            device=device,
            requires_grad=requires_grad,
        )  # pyright: ignore[reportCallIssue]
        return frBbox(bbox)
    elif isinstance(py_obj, list) and isinstance(py_obj[0], list) and len(py_obj[0]) == 4:  # not working in pycocotools
        bbox_list = [
            torch.tensor(obj, dtype=torch.int32, device=device, requires_grad=requires_grad if requires_grad else False)
            for obj in py_obj
        ]
        data = torch.stack(bbox_list)
        boxes = tv.BoundingBoxes(
            data, format=tv.BoundingBoxFormat.XYWH, canvas_size=(h, w), device=device, requires_grad=requires_grad
        )  # pyright: ignore[reportCallIssue]
        return frBbox(boxes, device=device, requires_grad=requires_grad)
    elif isinstance(py_obj, list) and isinstance(py_obj[0], list) and len(py_obj[0]) > 4:
        poly_list = [
            Polygon(
                torch.tensor(
                    obj, dtype=torch.float64, device=device, requires_grad=requires_grad if requires_grad else False
                ).view(-1, 2),
                canvas_size=(h, w),
                device=device,
                requires_grad=requires_grad,
            )  # pyright: ignore[reportCallIssue]
            for obj in py_obj
        ]
        polygons = poly_list  # Polygons(poly_list)  # pyright: ignore[reportCallIssue]
        return frPoly(polygons, device=device, requires_grad=requires_grad)
    elif isinstance(py_obj, list) and any(
        isinstance(obj, RleObj | dict) and ("counts" in obj) and ("size" in obj) for obj in py_obj
    ):
        rle_objs = [RleObj(size=obj["size"], counts=obj["counts"]) for obj in cast(list, py_obj)]
        return frUncompressedRLE(rle_objs, device=device, requires_grad=requires_grad)
    # encode rle from single python object
    elif isinstance(py_obj, list) and len(py_obj) == 4:  # not working in pycocotools
        data = torch.tensor(
            [py_obj], dtype=torch.int32, device=device, requires_grad=requires_grad if requires_grad else False
        )
        boxes = tv.BoundingBoxes(
            data, format=tv.BoundingBoxFormat.XYWH, canvas_size=(h, w), device=device, requires_grad=requires_grad
        )  # pyright: ignore[reportCallIssue]
        return frBbox(boxes, device=device, requires_grad=requires_grad)[0]
    elif isinstance(py_obj, list) and len(py_obj) > 4:
        poly = Polygon(
            torch.tensor(
                py_obj, dtype=torch.float64, device=device, requires_grad=requires_grad if requires_grad else False
            ).view(-1, 2),
            canvas_size=(h, w),
            device=device,
            requires_grad=requires_grad,
        )  # pyright: ignore[reportCallIssue]
        polygons = [poly]  # Polygons([poly])  # pyright: ignore[reportCallIssue]
        return frPoly(polygons, device=device, requires_grad=requires_grad)[0]
    elif isinstance(py_obj, RleObj | dict) and "counts" in py_obj and "size" in py_obj:
        return frUncompressedRLE(
            [RleObj(size=py_obj["size"], counts=py_obj["counts"])], device=device, requires_grad=requires_grad
        )[0]
    else:
        raise Exception("Input type is not supported.")  # noqa: TRY002
