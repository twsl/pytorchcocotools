from typing import cast

import torch
from torch import Tensor
from torchvision import tv_tensors as tv

from pytorchcocotools.internal.entities import RLE, IoUObject, Poly, PyObj, RleObj, RleObjs, RLEs, TorchDevice
from pytorchcocotools.internal.mask_api import (
    bbIou,
    rleArea,
    rleDecode,
    rleEncode,
    rleFrBbox,
    rleFrPoly,
    rleFrString,
    rleIou,
    rleMerge,
    rleToBbox,
    rleToString,
)
from pytorchcocotools.utils.poly import Polygon


def _toString(  # noqa: N802
    rles: RLEs,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObjs:
    """Internal conversion from Python RLEs object to compressed RLE format.

    Args:
        rles: The masks to encode.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The RLE encoded mask.
    """
    objs = [
        RleObj(
            size=[r.h, r.w],
            counts=rleToString(
                r,
                device=device,
                requires_grad=requires_grad,
            ),
        )
        for r in rles
    ]
    return objs


def _frString(  # noqa: N802
    rle_objs: RleObjs,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RLEs:
    """Internal conversion from compressed RLE format to Python RLEs object.

    Args:
        rle_objs: List of rle encoded masks.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The decoded mask.
    """
    rles = [
        rleFrString(
            str.encode(obj.counts) if isinstance(obj.counts, str) else obj.counts,
            obj.size[0],
            obj.size[1],
            device=device,
            requires_grad=requires_grad,
        )
        for obj in rle_objs
    ]
    return rles


def encode(
    mask: tv.Mask,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObjs:
    """Encode mask to RLEs objects, list of RLE string can be generated by RLEs member function.

    Args:
        mask: The mask to encode.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The encoded mask.
    """
    # np.ndarray[np.uint8_t, ndim=3, mode='fortran']
    rles = rleEncode(mask, device=device, requires_grad=requires_grad)
    rle_objs = _toString(rles, device=device, requires_grad=requires_grad)
    return rle_objs


def decode(
    rle_objs: RleObjs,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> tv.Mask:
    """Decode mask from compressed list of RLE string or RLEs object.

    Args:
        rle_objs: The encoded masks.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The decoded mask.
    """
    rles = _frString(rle_objs, device=device, requires_grad=requires_grad)
    masks = rleDecode(rles, device=device, requires_grad=requires_grad)
    return masks


def merge(
    rle_objs: RleObjs,
    intersect: bool = False,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObj:
    """Merges multiple rles into one rle mask by taking union (OR) or intersection (AND).

    Args:
        rle_objs: The masks to merge.
        intersect: Whether to compute the intersection.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The merged mask.
    """
    rs = _frString(rle_objs, device=device, requires_grad=requires_grad)
    r = rleMerge(rs, intersect, device=device, requires_grad=requires_grad)
    obj = _toString([r], device=device, requires_grad=requires_grad)[0]
    return obj


def area(
    rle_objs: RleObjs,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> list[int]:
    """Compute area of encoded masks.

    Args:
        rle_objs: The masks to compute the area of.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        A list of areas of the encoded masks.
    """
    rs = _frString(rle_objs, device=device, requires_grad=requires_grad)
    a = rleArea(rs, device=device, requires_grad=requires_grad)
    return a


def iou(
    dt: IoUObject,
    gt: IoUObject,
    pyiscrowd: list[bool],
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> Tensor:
    """Compute intersection over union between objects.

    Note:
    Supports function overload (RLEs-RLEs and bbox-bbox)

    Args:
        dt: The detected objects.
        gt: The ground truth objects.
        pyiscrowd: The iscrowd flag for each object.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The intersection over union between the detected and ground truth objects.
    """

    def _preproc(objs: IoUObject) -> Tensor | RLEs:
        if len(objs) == 0:
            return Tensor(objs)
        if isinstance(objs, Tensor):
            if len(objs.shape) == 1:
                # TODO: figure out, why pycocotools didn't use the shape, propably just another error?
                # objs = objs.reshape((objs[0], 1))
                objs = objs.reshape((objs.shape[0], 1))
            # check if it's Nx4 bbox
            if not len(objs.shape) == 2 or not objs.shape[1] == 4:
                raise Exception("Tensor input is only for *bounding boxes* and should have Nx4 dimension")  # noqa: TRY002
            objs = objs.to(dtype=torch.float32)  # TODO: originally double is used, why???
        elif isinstance(objs, list):
            # check if list is in box format and convert it to torch.Tensor
            isbox = all((isinstance(obj, list | Tensor)) and (len(obj) == 4) for obj in objs)
            isrle = all(isinstance(obj, dict) for obj in objs)
            if isbox:
                objs = torch.tensor(objs, dtype=torch.float32)
                if len(objs.shape) == 1:
                    objs = objs.reshape((1, objs.shape[0]))
            elif isrle:
                objs = _frString(objs)  # pyright: ignore[reportArgumentType]
            else:
                raise Exception("list input can be bounding box (Nx4) or RLEs ([RLE])")  # noqa: TRY002
        else:
            raise TypeError(
                "Unrecognized type. The following type: RLEs (rle), torch.Tensor (box), and list (box) are supported."
            )
        return objs

    is_crowd = pyiscrowd
    dt = _preproc(dt)
    gt = _preproc(gt)
    m = len(dt)
    n = len(gt)
    crowd_length = len(is_crowd)
    assert crowd_length == n, "iou(iscrowd=) must have the same length as gt"  # noqa: S101
    if m == 0 or n == 0:
        return Tensor()
    if type(dt) is not type(gt):
        raise Exception("The dt and gt should have the same data type, either RLEs, list or torch.Tensor")  # noqa: TRY002
    if isinstance(dt, RLEs) and isinstance(gt, RLEs):  # pyright: ignore[reportArgumentType] # TODO: fix check
        return rleIou(dt, gt, is_crowd)
    if isinstance(dt, tv.BoundingBoxes) and isinstance(gt, tv.BoundingBoxes):
        return bbIou(dt, gt, is_crowd)
    else:
        raise TypeError("Input data type not allowed.")  # noqa: TRY002
    return Tensor()


def toBbox(  # noqa: N802
    rle_objs: RleObjs,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> tv.BoundingBoxes:
    """Compute bounding box from encoded objects.

    Args:
        rle_objs: The masks to compute the bounding box of.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The bounding box of the encoded masks.
    """
    rs = _frString(rle_objs, device=device, requires_grad=requires_grad)
    bb = rleToBbox(rs, device=device, requires_grad=requires_grad)
    return bb


def frBbox(  # noqa: N802
    bb: tv.BoundingBoxes,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObjs:
    """Convert bounding box to run length encoded objects.

    Args:
        bb: The bounding box to convert.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The RLE encoded objects.
    """
    rs = rleFrBbox(bb, device=device, requires_grad=requires_grad)
    objs = _toString(rs, device=device, requires_grad=requires_grad)
    return objs


def frPoly(  # noqa: N802
    poly: list[Poly] | Polygon,
    h: int,
    w: int,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObjs:
    """Convert polygon to run length encoded objects.

    Args:
        poly: The polygon to convert.
        h: The height of the mask.
        w: The width of the mask.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The RLE encoded objects.
    """
    rs = []  # RLEs(n)
    for p in poly:
        np_poly = (
            p
            if isinstance(p, Polygon)
            else Polygon(
                torch.tensor(p, dtype=torch.float64),
                canvas_size=(h, w),
            )  # pyright: ignore[reportCallIssue]
        )
        rs.append(rleFrPoly(np_poly, device=device, requires_grad=requires_grad))
    objs = _toString(RLEs(rs))
    return RleObjs(objs)


def frUncompressedRLE(  # noqa: N803, N802
    uc_rles: RleObjs,
    h: int,
    w: int,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObjs:
    """Convert uncompressed RLE to run length encoded objects.

    Args:
        uc_rles: The uncompressed RLE to convert.
        h: The height of the mask.
        w: The width of the mask.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Returns:
        The RLE encoded objects.
    """
    n = len(uc_rles)
    objs = []
    for i in range(n):
        cnts = torch.tensor(uc_rles[i].counts, dtype=torch.int)
        r = RLE(uc_rles[i].size[0], uc_rles[i].size[1], cnts)
        objs.append(_toString(RLEs([r]), device=device, requires_grad=requires_grad)[0])
    return objs


def frPyObjects(  # noqa: N802
    py_obj: PyObj,
    h: int,
    w: int,
    *,
    device: TorchDevice | None = None,
    requires_grad: bool | None = None,
) -> RleObjs | RleObj:
    """Convert (list of) polygon, bbox, or uncompressed RLE to encoded RLE mask.

    Args:
        py_obj: The object(s) to convert.
        h: The height of the mask.
        w: The width of the mask.
        device: The desired device of the bounding boxes.
        requires_grad: Whether the bounding boxes require gradients.

    Raises:
        Exception: Input type is not supported.

    Returns:
        The encoded mask.
    """
    # encode rle from a list of python objects
    if isinstance(py_obj, tv.BoundingBoxes):
        return frBbox(py_obj)
    elif isinstance(py_obj, list) and isinstance(py_obj[0], list) and len(py_obj[0]) == 4:  # not working in pycocotools
        data = torch.stack([torch.tensor(obj, dtype=torch.int32) for obj in py_obj])
        boxes = tv.BoundingBoxes(data, format=tv.BoundingBoxFormat.XYWH, canvas_size=(h, w))  # pyright: ignore[reportCallIssue]
        return frBbox(boxes, device=device, requires_grad=requires_grad)
    elif isinstance(py_obj, list) and isinstance(py_obj[0], list) and len(py_obj[0]) > 4:
        return frPoly(cast(list[Poly], py_obj), h, w, device=device, requires_grad=requires_grad)
    elif isinstance(py_obj, list) and isinstance(py_obj[0], RleObj):
        return frUncompressedRLE(cast(RleObjs, py_obj), h, w, device=device, requires_grad=requires_grad)
    # encode rle from single python object
    elif isinstance(py_obj, list) and len(py_obj) == 4:  # not working in pycocotools
        data = Tensor([py_obj])
        boxes = tv.BoundingBoxes(data, format=tv.BoundingBoxFormat.XYWH, canvas_size=(h, w))  # pyright: ignore[reportCallIssue]
        return frBbox(boxes, device=device, requires_grad=requires_grad)[0]
    elif isinstance(py_obj, list) and len(py_obj) > 4:
        return frPoly([cast(Poly, py_obj)], h, w, device=device, requires_grad=requires_grad)[0]
    elif isinstance(py_obj, dict) and "counts" in py_obj and "size" in py_obj:
        return frUncompressedRLE([RleObj(py_obj)], h, w, device=device, requires_grad=requires_grad)[0]
    else:
        raise Exception("Input type is not supported.")  # noqa: TRY002
